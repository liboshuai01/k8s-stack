---

apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  namespace: flink
  name: application-example  # flink 集群名称
spec:
  image: flink:1.18.0-java8
  flinkVersion: v1_18
  imagePullPolicy: IfNotPresent
  ingress:
    template: "flink.lbs.com/{{namespace}}/{{name}}(/|$)(.*)"
    className: "nginx"
    annotations:
      nginx.ingress.kubernetes.io/rewrite-target: "/$2"
  flinkConfiguration:
    # 槽
    taskmanager.numberOfTaskSlots: "2"
    # checkpoint 路径
    state.checkpoints.dir: file:///opt/flink/checkpoints
    # 高可用
    high-availability.type: kubernetes
    high-availability: org.apache.flink.kubernetes.highavailability.KubernetesHaServicesFactory # JobManager HA
    high-availability.storageDir: file:///opt/flink/flink_recovery  # JobManager HA数据保存路径
    jobmanager.archive.fs.dir: file:///opt/flink/flink_history      # JobManager 归档路径
    # 历史服务器
    historyserver.archive.fs.dir: file:///opt/flink/flink_history      # Historyserver 归档路径
    historyserver.archive.fs.refresh-interval: "10000"              # Historyserver 文件刷新间隔
    # 自动扩缩容
    job.autoscaler.enabled: "true"  # 开启autoscaling
    job.autoscaler.stabilization.interval: 1m #稳定窗口。在此期间，不会收集任何指标，也不会采取任何缩放操作
    job.autoscaler.metrics.window: 2m #指标采集时间窗口
    job.autoscaler.target.utilization: "0.5"  #目标利用率，扩缩容后尽量确保作业或chained operator groups的利用率在此值以下
    job.autoscaler.target.utilization.boundary: "0.1"  #利用率边界，避免负载波动时立即扩缩容。0.1意味着在触发缩放操作之前，允许与目标利用率有10%的偏差
    job.autoscaler.restart.time: 1m #重新启动应用程序需要的时间
    job.autoscaler.catch-up.duration: 2m #扩容后，作业有望赶上的时间
    pipeline.max-parallelism: "24" # 扩容到的最大并行度
    # 其他参数配置
    taskmanager.memory.managed.size: 0m  # 配置托管内存为0（状态后端为内存时启用）
    rest.flamegraph.enabled: true  # 开启火焰图
  serviceAccount: flink
  jobManager:
    replicas: 2  # HA下， jobManger的副本数要大于1
    resource:
      # 推荐生产环境最小配置为4g
      memory: "1024m"
      # 推荐生产环境最小配置为1
      cpu: 1
  taskManager:
    replicas: 1
    resource:
      # 推荐生产环境最小配置为4g
      memory: "1024m"
      # 推荐生产环境最小配置为1（小于1也不能生效）
      cpu: 1
  podTemplate:
    spec:
      hostAliases:
        - ip: "192.168.6.132"
          hostnames:
            - "master"
        - ip: "192.168.6.135"
          hostnames:
            - "node1"
        - ip: "192.168.6.136"
          hostnames:
            - "node2"
      containers:
        - name: flink-main-container
          env:
            - name: TZ
              value: Asia/Shanghai
          volumeMounts:
            - name: flink-jar  # 挂载nfs上的jar
              mountPath: /opt/flink/jar
            - name: flink-checkpoints  # 挂载checkpoint pvc
              mountPath: /opt/flink/checkpoints
              # 取消本地持久化日志，转用elk采集
#            - name: flink-log  # 挂载日志 pvc
#              mountPath: /opt/flink/log
            - name: flink-ha    # HA pvc配置
              mountPath: /opt/flink/flink_recovery
            - name: flink-historyserver # 历史服务器 pvc配置
              mountPath: /opt/flink/flink_history
      volumes:
        - name: flink-jar
          persistentVolumeClaim:
            claimName: flink-jar-pvc
        - name: flink-checkpoints
          persistentVolumeClaim:
            claimName: flink-checkpoint-application-pvc
          # 取消本地持久化日志，转用elk采集
#        - name: flink-log
#          persistentVolumeClaim:
#            claimName: flink-log-pvc
        - name: flink-ha
          persistentVolumeClaim:
            claimName: flink-ha-pvc
        - name: flink-historyserver
          persistentVolumeClaim:
            claimName: flink-historyserver-pvc
  job:
    jarURI: local:///opt/flink/jar/flink-wordcount.jar # 使用pv方式挂载jar包
    entryClass: com.liboshuai.demo.FlinkWordCountDemo
    args:   # 传递到作业main方法的参数（parallelism为并行度关键参数）
      - "--parallelism"
      - "4"
      - "--hostname"
      - "master"
      - "--port"
      - "9999"
    # （默认使用1即可，不需要修改）
    parallelism: 1
    upgradeMode: stateless

